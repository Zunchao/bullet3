!!python/object/new:pybullet_envs.agents.tools.attr_dict.AttrDict
dictitems:
  algorithm: !!python/name:pybullet_envs.agents.ppo.algorithm.PPOAlgorithm ''
  discount: 0.995
  env: !!python/object/apply:functools.partial
    args:
    - &id001 !!python/name:pybullet_envs.bullet.minitaur_gym_env.MinitaurBulletEnv ''
    state: !!python/tuple
    - *id001
    - !!python/tuple []
    - accurate_motor_model_enabled: true
      env_randomizer: &id002 !!python/object:pybullet_envs.bullet.minitaur_env_randomizer.MinitaurEnvRandomizer
        _battery_voltage_range: !!python/tuple
        - 14.8
        - 16.8
        _minitaur_base_mass_err_range: !!python/tuple
        - -0.2
        - 0.2
        _minitaur_leg_mass_err_range: !!python/tuple
        - -0.2
        - 0.2
        _motor_viscous_damping_range: !!python/tuple
        - 0
        - 0.01
      motor_overheat_protection: true
      pd_control_enabled: true
      render: false
    - null
  eval_episodes: 30
  init_logstd: -1
  init_mean_factor: 0.1
  kl_cutoff_coef: 1000
  kl_cutoff_factor: 2
  kl_init_penalty: 1
  kl_target: 0.01
  learning_rate: 0.0001
  logdir: mmkukahusky/20190102T184407-pybullet_minitaur
  max_length: 1000
  network: !!python/name:pybullet_envs.agents.networks.feed_forward_gaussian ''
  num_agents: 30
  optimizer: !!python/name:tensorflow.python.training.adam.AdamOptimizer ''
  policy_layers: !!python/tuple
  - 200
  - 100
  randomizer: *id002
  steps: 30000000.0
  update_epochs: 25
  update_epochs_policy: 64
  update_epochs_value: 64
  update_every: 30
  use_gpu: false
  value_layers: !!python/tuple
  - 200
  - 100
  weight_summaries:
    all: .*
    policy: .*/policy/.*
    value: .*/value/.*
state:
  _mutable: false
